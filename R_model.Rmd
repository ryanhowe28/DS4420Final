---
title: "R Notebook"
output: html_notebook
---

This is an [R Markdown](http://rmarkdown.rstudio.com) Notebook. When you execute code within the notebook, the results appear beneath the code. 

Try executing this chunk by clicking the *Run* button within the chunk or by placing your cursor inside it and pressing *Cmd+Shift+Enter*. 

```{r}
# If not installed, first run:
# install.packages("torch")
# install.packages("torchvision")

library(torch)
library(torchvision)
library(dplyr)

packageVersion("torch")
packageVersion("torchvision")

# ------------------------------------------------------------------
# 1. Download or set the path to your dataset
# ------------------------------------------------------------------
# In Python, you used:
#   path = kagglehub.dataset_download("mahmoudreda55/satellite-image-classification")
# Here, adjust "path" so it points to the data folder on your system.
# For instance:
path <- "/path/to/mahmoudreda55/satellite-image-classification"

cat("Path to dataset files:", path, "\n")

# ------------------------------------------------------------------
# 2. Basic transform and dataset creation
# ------------------------------------------------------------------
# Rough equivalent of transforms.Resize((224,224)) and transforms.ToTensor()
basic_transform <- transforms_compose(list(
  transform_resize(size = c(224, 224)),
  transform_to_tensor()
))

dataset <- image_folder_dataset(
  root = file.path(path, "data"),
  transform = basic_transform
)

loader <- dataloader(dataset, batch_size = 32, shuffle = TRUE)

# ------------------------------------------------------------------
# 3. Show a few samples (images + labels)
# ------------------------------------------------------------------
# In Python, you looped for i in range(5). R is 1-based indexing.
for (i in seq_len(5)) {
  sample <- dataset[i]
  image <- sample[[1]]    # A torch_tensor
  label <- sample[[2]]    # An integer label

  cat("Label:", dataset$classes[[label]], "\n")

  # Convert from C x H x W to H x W x C and display
  image_np <- as.array(image$permute(c(2, 3, 1)))
  
  # Display the image with base R
  # (For more advanced plotting, you can use the 'magick' or 'EBImage' packages)
  plot(as.raster(image_np))
  title(paste("Class:", dataset$classes[[label]]))
}

# ------------------------------------------------------------------
# 4. Create a data frame of file paths and labels
#    (Similar to pd.DataFrame(dataset.samples, ...)
# ------------------------------------------------------------------
df <- data.frame(
  image_path = dataset$files,
  label_index = dataset$labels
)

df$class_name <- dataset$classes[df$label_index]

head(df)
print(dataset$classes)

# ------------------------------------------------------------------
# 5. Preprocessing / Augmentations
# ------------------------------------------------------------------
# Python:
#   transforms.RandomHorizontalFlip, transforms.RandomRotation, ...
# R 'torchvision' provides the following transforms we can chain together:
train_transform <- transform_list(
  transform_resize(size = c(224, 224)),
  transform_random_horizontal_flip(p = 0.5),
  transform_random_rotation(degrees = 15),
  transform_color_jitter(
    brightness = 0.2,
    contrast   = 0.2,
    saturation = 0.2,
    hue        = 0.1
  ),
  transform_to_tensor(),
  transform_normalize(
    mean = c(0.485, 0.456, 0.406),
    std  = c(0.229, 0.224, 0.225)
  )
)

valid_transform <- transform_list(
  transform_resize(size = c(224, 224)),
  transform_to_tensor(),
  transform_normalize(
    mean = c(0.485, 0.456, 0.406),
    std  = c(0.229, 0.224, 0.225)
  )
)

# ------------------------------------------------------------------
# 6. Split into training and validation sets
# ------------------------------------------------------------------
full_dataset <- image_folder_dataset(
  root = file.path(path, "data"),
  transform = NULL  # We'll apply transforms below
)

set.seed(123)
dataset_size <- length(full_dataset)
train_size   <- floor(0.8 * dataset_size)
valid_size   <- dataset_size - train_size

indices       <- sample.int(dataset_size)
train_indices <- indices[seq_len(train_size)]
valid_indices <- indices[(train_size + 1):dataset_size]

train_dataset <- dataset_subset(full_dataset, indices = train_indices)
valid_dataset <- dataset_subset(full_dataset, indices = valid_indices)

# Apply the transforms
train_dataset$.transform <- train_transform
valid_dataset$.transform <- valid_transform

# ------------------------------------------------------------------
# 7. Create data loaders
# ------------------------------------------------------------------
batch_size <- 32

train_loader <- dataloader(train_dataset, batch_size = batch_size, shuffle = TRUE)
valid_loader <- dataloader(valid_dataset, batch_size = batch_size, shuffle = FALSE)

# ------------------------------------------------------------------
# 8. Checking a batch
# ------------------------------------------------------------------
batch <- dataloader_make_iter(train_loader) %>% dataloader_next()
sample_images <- batch[[1]]
sample_labels <- batch[[2]]

cat("Batch shape:", dim(sample_images), "\n") 
# This should show (batch_size, channels, height, width).

# Show a few images from the batch
num_to_show <- min(5, dim(sample_images)[1])
for (i in seq_len(num_to_show)) {
  image <- sample_images[i, , , , drop = FALSE] 
  label <- sample_labels[i]

  # Convert to H x W x C
  image_np <- as.array(image$permute(c(2, 3, 1)))

  class_name <- full_dataset$classes[[as.integer(label)]]
  plot(as.raster(image_np))
  title(paste("Class:", class_name))
}

# ------------------------------------------------------------------
# 9. View DataFrame for the full dataset
# ------------------------------------------------------------------
samples_full_df <- data.frame(
  image_path  = full_dataset$files,
  label_index = full_dataset$labels
)
samples_full_df$class_name <- full_dataset$classes[samples_full_df$label_index]

head(samples_full_df)
cat("Classes:\n")
print(full_dataset$classes)

```

Add a new chunk by clicking the *Insert Chunk* button on the toolbar or by pressing *Cmd+Option+I*.

When you save the notebook, an HTML file containing the code and output will be saved alongside it (click the *Preview* button or press *Cmd+Shift+K* to preview the HTML file). 

The preview shows you a rendered HTML copy of the contents of the editor. Consequently, unlike *Knit*, *Preview* does not run any R code chunks. Instead, the output of the chunk when it was last run in the editor is displayed.

